{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.regularizers import l2\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "         id.orig_addr  id.orig_port  id.resp_haddr  id.resp_pport  proto_enum  \\\n0          3232235972         48438     2300985238             23           1   \n1          3232235972         33878     1352962162             23           1   \n2          3232235972         55416     1539874379             23           1   \n3          3232235972         47778     2258007740             23           1   \n4          3232235972         46752     1732534418             23           1   \n...               ...           ...            ...            ...         ...   \n2314090    3232235971         59699     2734184663          62336           1   \n2314091    3232235971         32909     2734184663          62336           1   \n2314092    3232235971         25120     2734184663          62336           1   \n2314093    3232235971         30340     2734184663          62336           1   \n2314094    3232235971           678     2734184663          62336           1   \n\n         duration_interval  conn_state_string  orig_pkts_count  \\\n0                 5.030600                  4                1   \n1                 3.089012                  4                3   \n2                 3.089276                  4                3   \n3                 5.030600                  4                1   \n4                 3.130498                  4                3   \n...                    ...                ...              ...   \n2314090           5.030600                  0                0   \n2314091           5.030600                  0                0   \n2314092           5.030600                  0                0   \n2314093           5.030600                  0                0   \n2314094           5.030600                  0                0   \n\n         orig_ip_bytes_count  resp_pkts_count  resp_bytes  Category  \n0                         60                0           0         0  \n1                        180                0           0         0  \n2                        180                0           0         0  \n3                         60                0           0         0  \n4                        180                0           0         0  \n...                      ...              ...         ...       ...  \n2314090                    0                0           0         1  \n2314091                    0                0           0         1  \n2314092                    0                0           0         1  \n2314093                    0                0           0         1  \n2314094                    0                0           0         1  \n\n[2314095 rows x 12 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id.orig_addr</th>\n      <th>id.orig_port</th>\n      <th>id.resp_haddr</th>\n      <th>id.resp_pport</th>\n      <th>proto_enum</th>\n      <th>duration_interval</th>\n      <th>conn_state_string</th>\n      <th>orig_pkts_count</th>\n      <th>orig_ip_bytes_count</th>\n      <th>resp_pkts_count</th>\n      <th>resp_bytes</th>\n      <th>Category</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>3232235972</td>\n      <td>48438</td>\n      <td>2300985238</td>\n      <td>23</td>\n      <td>1</td>\n      <td>5.030600</td>\n      <td>4</td>\n      <td>1</td>\n      <td>60</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>3232235972</td>\n      <td>33878</td>\n      <td>1352962162</td>\n      <td>23</td>\n      <td>1</td>\n      <td>3.089012</td>\n      <td>4</td>\n      <td>3</td>\n      <td>180</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3232235972</td>\n      <td>55416</td>\n      <td>1539874379</td>\n      <td>23</td>\n      <td>1</td>\n      <td>3.089276</td>\n      <td>4</td>\n      <td>3</td>\n      <td>180</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3232235972</td>\n      <td>47778</td>\n      <td>2258007740</td>\n      <td>23</td>\n      <td>1</td>\n      <td>5.030600</td>\n      <td>4</td>\n      <td>1</td>\n      <td>60</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>3232235972</td>\n      <td>46752</td>\n      <td>1732534418</td>\n      <td>23</td>\n      <td>1</td>\n      <td>3.130498</td>\n      <td>4</td>\n      <td>3</td>\n      <td>180</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>2314090</th>\n      <td>3232235971</td>\n      <td>59699</td>\n      <td>2734184663</td>\n      <td>62336</td>\n      <td>1</td>\n      <td>5.030600</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2314091</th>\n      <td>3232235971</td>\n      <td>32909</td>\n      <td>2734184663</td>\n      <td>62336</td>\n      <td>1</td>\n      <td>5.030600</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2314092</th>\n      <td>3232235971</td>\n      <td>25120</td>\n      <td>2734184663</td>\n      <td>62336</td>\n      <td>1</td>\n      <td>5.030600</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2314093</th>\n      <td>3232235971</td>\n      <td>30340</td>\n      <td>2734184663</td>\n      <td>62336</td>\n      <td>1</td>\n      <td>5.030600</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2314094</th>\n      <td>3232235971</td>\n      <td>678</td>\n      <td>2734184663</td>\n      <td>62336</td>\n      <td>1</td>\n      <td>5.030600</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>2314095 rows × 12 columns</p>\n</div>"
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the dataset\n",
    "df_ben_ddos = pd.read_csv('df_ben_ddos.csv')\n",
    "df_ben_ddos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "         id.orig_addr  id.orig_port  id.resp_haddr  id.resp_pport  proto_enum  \\\n46730      3296074089          5151     2022758712             53           2   \n48393      3296074089         61215      820700452             53           2   \n41416      3296074089         60587     1658561341             53           2   \n34506      3232235972         52092     2210836888             23           1   \n43725      3296074089          5566     3818472118             53           2   \n...               ...           ...            ...            ...         ...   \n301298     3232235972          6627     3512843912             80           1   \n2294362    3232235971         25797     2734184663          62336           1   \n926346     3232235972         20778     3512843912             22           1   \n626152     3232235972         26001     3512843912             80           1   \n1142082    3232235972         58409      908547944            992           1   \n\n         duration_interval  conn_state_string  orig_pkts_count  \\\n46730             5.030600                  4                1   \n48393             5.030600                  4                1   \n41416             5.030600                  4                1   \n34506             3.119981                  4                3   \n43725             5.030600                  4                1   \n...                    ...                ...              ...   \n301298            4.591175                  3                2   \n2294362           5.030600                  0                0   \n926346           95.031517                  0               62   \n626152            4.856502                  3                4   \n1142082           4.987876                  3                5   \n\n         orig_ip_bytes_count  resp_pkts_count  resp_bytes  Category  \n46730                    540                0           0         0  \n48393                    540                0           0         0  \n41416                    540                0           0         0  \n34506                    180                0           0         0  \n43725                    540                0           0         0  \n...                      ...              ...         ...       ...  \n301298                    80                0           0         1  \n2294362                    0                0           0         1  \n926346                  3100                0           0         1  \n626152                   160                0           0         1  \n1142082                  200                0           0         1  \n\n[100000 rows x 12 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id.orig_addr</th>\n      <th>id.orig_port</th>\n      <th>id.resp_haddr</th>\n      <th>id.resp_pport</th>\n      <th>proto_enum</th>\n      <th>duration_interval</th>\n      <th>conn_state_string</th>\n      <th>orig_pkts_count</th>\n      <th>orig_ip_bytes_count</th>\n      <th>resp_pkts_count</th>\n      <th>resp_bytes</th>\n      <th>Category</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>46730</th>\n      <td>3296074089</td>\n      <td>5151</td>\n      <td>2022758712</td>\n      <td>53</td>\n      <td>2</td>\n      <td>5.030600</td>\n      <td>4</td>\n      <td>1</td>\n      <td>540</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>48393</th>\n      <td>3296074089</td>\n      <td>61215</td>\n      <td>820700452</td>\n      <td>53</td>\n      <td>2</td>\n      <td>5.030600</td>\n      <td>4</td>\n      <td>1</td>\n      <td>540</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>41416</th>\n      <td>3296074089</td>\n      <td>60587</td>\n      <td>1658561341</td>\n      <td>53</td>\n      <td>2</td>\n      <td>5.030600</td>\n      <td>4</td>\n      <td>1</td>\n      <td>540</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>34506</th>\n      <td>3232235972</td>\n      <td>52092</td>\n      <td>2210836888</td>\n      <td>23</td>\n      <td>1</td>\n      <td>3.119981</td>\n      <td>4</td>\n      <td>3</td>\n      <td>180</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>43725</th>\n      <td>3296074089</td>\n      <td>5566</td>\n      <td>3818472118</td>\n      <td>53</td>\n      <td>2</td>\n      <td>5.030600</td>\n      <td>4</td>\n      <td>1</td>\n      <td>540</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>301298</th>\n      <td>3232235972</td>\n      <td>6627</td>\n      <td>3512843912</td>\n      <td>80</td>\n      <td>1</td>\n      <td>4.591175</td>\n      <td>3</td>\n      <td>2</td>\n      <td>80</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2294362</th>\n      <td>3232235971</td>\n      <td>25797</td>\n      <td>2734184663</td>\n      <td>62336</td>\n      <td>1</td>\n      <td>5.030600</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>926346</th>\n      <td>3232235972</td>\n      <td>20778</td>\n      <td>3512843912</td>\n      <td>22</td>\n      <td>1</td>\n      <td>95.031517</td>\n      <td>0</td>\n      <td>62</td>\n      <td>3100</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>626152</th>\n      <td>3232235972</td>\n      <td>26001</td>\n      <td>3512843912</td>\n      <td>80</td>\n      <td>1</td>\n      <td>4.856502</td>\n      <td>3</td>\n      <td>4</td>\n      <td>160</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1142082</th>\n      <td>3232235972</td>\n      <td>58409</td>\n      <td>908547944</td>\n      <td>992</td>\n      <td>1</td>\n      <td>4.987876</td>\n      <td>3</td>\n      <td>5</td>\n      <td>200</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>100000 rows × 12 columns</p>\n</div>"
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sampled dataset, it could be either random rows or 10k from beningn and 10k from malicious to balance the trained dataset\n",
    "#df_sampled = df_ben_ddos.sample(frac=0.01, random_state=42)\n",
    "df_first = df_ben_ddos[:70000].sample(n=50000, random_state=42)\n",
    "df_last = df_ben_ddos[80000:].sample(n=50000, random_state=42)\n",
    "df_sampled = pd.concat([df_first, df_last])\n",
    "df_sampled\n",
    "\n",
    "# min_values = []\n",
    "# max_values = []\n",
    "# for col in df_sampled:\n",
    "#\n",
    "#     min_values.append(min(df_sampled[col]))\n",
    "#     max_values.append(max(df_sampled[col]))\n",
    "#\n",
    "# print(min_values)\n",
    "# print(max_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "         id.orig_port  id.resp_pport  proto_enum  duration_interval  \\\n46730            5151             53           2           5.030600   \n48393           61215             53           2           5.030600   \n41416           60587             53           2           5.030600   \n34506           52092             23           1           3.119981   \n43725            5566             53           2           5.030600   \n...               ...            ...         ...                ...   \n301298           6627             80           1           4.591175   \n2294362         25797          62336           1           5.030600   \n926346          20778             22           1          95.031517   \n626152          26001             80           1           4.856502   \n1142082         58409            992           1           4.987876   \n\n         conn_state_string  orig_pkts_count  orig_ip_bytes_count  \\\n46730                    4                1                  540   \n48393                    4                1                  540   \n41416                    4                1                  540   \n34506                    4                3                  180   \n43725                    4                1                  540   \n...                    ...              ...                  ...   \n301298                   3                2                   80   \n2294362                  0                0                    0   \n926346                   0               62                 3100   \n626152                   3                4                  160   \n1142082                  3                5                  200   \n\n         resp_pkts_count  resp_bytes  \n46730                  0           0  \n48393                  0           0  \n41416                  0           0  \n34506                  0           0  \n43725                  0           0  \n...                  ...         ...  \n301298                 0           0  \n2294362                0           0  \n926346                 0           0  \n626152                 0           0  \n1142082                0           0  \n\n[100000 rows x 9 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id.orig_port</th>\n      <th>id.resp_pport</th>\n      <th>proto_enum</th>\n      <th>duration_interval</th>\n      <th>conn_state_string</th>\n      <th>orig_pkts_count</th>\n      <th>orig_ip_bytes_count</th>\n      <th>resp_pkts_count</th>\n      <th>resp_bytes</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>46730</th>\n      <td>5151</td>\n      <td>53</td>\n      <td>2</td>\n      <td>5.030600</td>\n      <td>4</td>\n      <td>1</td>\n      <td>540</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>48393</th>\n      <td>61215</td>\n      <td>53</td>\n      <td>2</td>\n      <td>5.030600</td>\n      <td>4</td>\n      <td>1</td>\n      <td>540</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>41416</th>\n      <td>60587</td>\n      <td>53</td>\n      <td>2</td>\n      <td>5.030600</td>\n      <td>4</td>\n      <td>1</td>\n      <td>540</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>34506</th>\n      <td>52092</td>\n      <td>23</td>\n      <td>1</td>\n      <td>3.119981</td>\n      <td>4</td>\n      <td>3</td>\n      <td>180</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>43725</th>\n      <td>5566</td>\n      <td>53</td>\n      <td>2</td>\n      <td>5.030600</td>\n      <td>4</td>\n      <td>1</td>\n      <td>540</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>301298</th>\n      <td>6627</td>\n      <td>80</td>\n      <td>1</td>\n      <td>4.591175</td>\n      <td>3</td>\n      <td>2</td>\n      <td>80</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2294362</th>\n      <td>25797</td>\n      <td>62336</td>\n      <td>1</td>\n      <td>5.030600</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>926346</th>\n      <td>20778</td>\n      <td>22</td>\n      <td>1</td>\n      <td>95.031517</td>\n      <td>0</td>\n      <td>62</td>\n      <td>3100</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>626152</th>\n      <td>26001</td>\n      <td>80</td>\n      <td>1</td>\n      <td>4.856502</td>\n      <td>3</td>\n      <td>4</td>\n      <td>160</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1142082</th>\n      <td>58409</td>\n      <td>992</td>\n      <td>1</td>\n      <td>4.987876</td>\n      <td>3</td>\n      <td>5</td>\n      <td>200</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>100000 rows × 9 columns</p>\n</div>"
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Separate features and target labels\n",
    "# X = df_sampled.drop(columns=['Category', 'id.resp_haddr', 'id.resp_pport', 'proto_enum', 'conn_state_string', 'resp_pkts_count', 'resp_bytes'])\n",
    "X = df_sampled.drop(columns=['Category', 'id.orig_addr', 'id.resp_haddr'])\n",
    "y = df_sampled['Category']\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/panagiotis04/Documents/Master Cybersecurity/First Semester/Traffic Monitor Analysis/Test/lib/python3.10/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# Define the neural network with stronger regularization and dropout\n",
    "model = Sequential([\n",
    "    Dense(64, input_dim=X_train.shape[1], activation='relu', kernel_regularizer=l2(0.01)),  # Stronger L2 regularization\n",
    "    Dropout(0.5),  # Increased dropout\n",
    "    Dense(32, activation='relu', kernel_regularizer=l2(0.01)),\n",
    "    Dropout(0.5),\n",
    "    Dense(1, activation='sigmoid')  # Binary classification output\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(optimizer='adam', \n",
    "              loss='binary_crossentropy', \n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add early stopping to prevent overfitting\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001B[1m1250/1250\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 2ms/step - accuracy: 0.9230 - loss: 0.5278 - val_accuracy: 0.9951 - val_loss: 0.1017\n",
      "Epoch 2/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_test, y_test),\n",
    "    epochs=100,  # Increase the number of epochs since early stopping is applied\n",
    "    batch_size=64,\n",
    "    callbacks=[early_stopping],  # Stop training when validation loss stops improving\n",
    "    verbose=1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model\n",
    "test_loss, test_accuracy = model.evaluate(X_test, y_test)\n",
    "print(f\"Test Loss: {test_loss}\")\n",
    "print(f\"Test Accuracy: {test_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot Training and Validation Loss\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Plot Training and Validation Accuracy\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on the test set\n",
    "y_pred = (model.predict(X_test) > 0.5).astype(int)  # Threshold of 0.5 for binary classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion Matrix\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Plot Confusion Matrix\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=['Class 0', 'Class 1'], yticklabels=['Class 0', 'Class 1'])\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification Report\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred, target_names=['Class 0', 'Class 1']))\n",
    "\n",
    "# ROC-AUC Score\n",
    "roc_auc = roc_auc_score(y_test, model.predict(X_test))\n",
    "print(f\"ROC-AUC Score: {roc_auc:.2f}\")\n",
    "model.save('nn.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import ipaddress\n",
    "import tensorflow as tf\n",
    "from keras import layers as l, models as m\n",
    "import numpy as np\n",
    "\n",
    "NOISE_DIM = 100\n",
    "COLUMNS = 9\n",
    "\n",
    "# id.orig_addr\tid.orig_port\tid.resp_haddr\tid.resp_pport\tproto_enum\tduration_interval\tconn_state_string\torig_pkts_count\torig_ip_bytes_count\tresp_pkts_count\tresp_bytes\n",
    "min_values = []\n",
    "max_values = []\n",
    "# X = id.orig_addr\tid.orig_port\tduration_interval\torig_pkts_count\torig_ip_bytes_count\n",
    "for col in X:\n",
    "\n",
    "    min_values.append(min(X[col]))\n",
    "    max_values.append(max(X[col]))\n",
    "\n",
    "array1 = np.array(min_values)\n",
    "array2 = np.array(max_values)\n",
    "# print(min_values)\n",
    "# print(max_values)\n",
    "\n",
    "# Features that will be used in the generator\n",
    "modifiable_features = ['id.orig_addr', 'id.orig_port', 'duration_interval', 'orig_pkts_count', 'orig_ip_bytes_count']\n",
    "\n",
    "# Features which values will remain fixed\n",
    "fixed_features = ['id.resp_haddr', 'id.resp_pport', 'proto_enum', 'conn_state_string', 'resp_pkts_count', 'resp_bytes']\n",
    "final_features = ['id.orig_addr','id.orig_port','id.resp_haddr','id.resp_pport','proto_enum','duration_interval','conn_state_string','orig_pkts_count','orig_ip_bytes_count','resp_pkts_count','resp_bytes', 'Category']\n",
    "# Extract the features from the dataset\n",
    "X_modifiable = X[:5]\n",
    "X_fixed = X[5:]\n",
    "\n",
    "def make_generator_model():\n",
    "    model = m.Sequential([\n",
    "        l.Input(shape=(NOISE_DIM,)),\n",
    "        l.Dense(64, activation='relu'),\n",
    "        l.Dense(32, activation='relu'),\n",
    "        l.Dense(COLUMNS, activation='tanh')\n",
    "    ])\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "BATCH_SIZE = 256\n",
    "\n",
    "cross_entropy = tf.keras.losses.BinaryCrossentropy()\n",
    "generator_optimizer = tf.keras.optimizers.Adam(1e-4)\n",
    "\n",
    "EPOCHS = 500\n",
    "\n",
    "generator = make_generator_model()\n",
    "discriminator = tf.keras.models.load_model('nn.h5')\n",
    "\n",
    "@tf.function\n",
    "def train_step():\n",
    "    noise = tf.random.normal([BATCH_SIZE, NOISE_DIM])\n",
    "\n",
    "    with tf.GradientTape() as gen_tape:\n",
    "        generated_flows = generator(noise, training=True)\n",
    "        fake_output = discriminator(generated_flows, training=False)\n",
    "        gen_loss = cross_entropy(tf.ones_like(fake_output), fake_output)\n",
    "\n",
    "    gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
    "    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
    "\n",
    "\n",
    "\n",
    "def denormalize_min_max(normalized_data):\n",
    "    denormalized_data = ((normalized_data + 1) / 2) * (array2 - array1) + array1\n",
    "    denormalized_data = [round(val) for val in denormalized_data]\n",
    "    denormalized_data[0] = str(ipaddress.IPv4Address(denormalized_data[0]))\n",
    "    return denormalized_data\n",
    "\n",
    "def get_trained_gan():\n",
    "    # Initialize a list to store the denormalized flows\n",
    "    denormalized_flows = []\n",
    "\n",
    "    for epoch in range(EPOCHS):\n",
    "        train_step()\n",
    "\n",
    "        seed = tf.random.normal([1, NOISE_DIM])\n",
    "        flow = generator(seed, training=False)\n",
    "\n",
    "        # Denormalize the flow\n",
    "        denormalized_flow = denormalize_min_max(flow[0].numpy())\n",
    "        # 'id.resp_haddr' this is the most repeated value 52879\n",
    "        d = str(ipaddress.IPv4Address(round(((52879 + 1) / 2) * (65272 - 0) + 0)))\n",
    "        # denormalized_flow.insert(2,d)\n",
    "        # 'id.resp_pport' is the most repeated port\n",
    "        # denormalized_flow.insert(3,80)\n",
    "        # 'proto_enum' most repeated\n",
    "        # denormalized_flow.insert(4,1)\n",
    "        # 'conn_state_string' most repeated is 3\n",
    "        # denormalized_flow.insert(6,3)\n",
    "        # 'resp_pkts_count' mean is 0.003\n",
    "        # denormalized_flow.insert(9,0)\n",
    "        # 'resp_bytes' mean is 2.28\n",
    "        # denormalized_flow.insert(10,2)\n",
    "        # label is 1\n",
    "        # denormalized_flow.append(1)\n",
    "       \n",
    "        # Append the denormalized flow to the list\n",
    "        denormalized_flows.append(denormalized_flow)\n",
    "\n",
    "        predicted = discriminator.predict(flow)\n",
    "        print(f\"Denormalised Flow {denormalized_flow}, {predicted}\")\n",
    "\n",
    "        # Optionally, print in a more readable format\n",
    "        # formatted_flow = [f\"{num:.2f}\" for num in denormalized_flow]\n",
    "        # print(f\"Denormalized Flow {formatted_flow}, {predicted}\")\n",
    "\n",
    "    # Convert the list of denormalized flows into a DataFrame\n",
    "    # df = pd.DataFrame(denormalized_flows, columns=final_features)\n",
    "\n",
    "    # Export the DataFrame to CSV\n",
    "    # df.to_csv(\"denormalized_flows.csv\")\n",
    "\n",
    "    return generator, discriminator\n",
    "\n",
    "# Train the GAN\n",
    "generator, discriminator = get_trained_gan()\n",
    "\n",
    "# Generate adversarial samples\n",
    "noise = tf.random.normal([len(X_test), NOISE_DIM])\n",
    "adversarial_samples = generator(noise, training=False)\n",
    "\n",
    "X\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ben_ddos['resp_pkts_count'].median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming adversarial_samples is a 1D array or list\n",
    "plt.plot(adversarial_samples, label='Adversarial Samples')\n",
    "plt.title('Adversarial Samples Generated')\n",
    "plt.xlabel('Sample Index')\n",
    "plt.ylabel('Value')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Evaluate classifier's performance on adversarial samples\n",
    "predictions_on_adversarial = discriminator.predict(adversarial_samples)\n",
    "print(\"Predictions on adversarial examples (discriminator output):\", predictions_on_adversarial[0])\n",
    "\n",
    "# To check detection evasion success:\n",
    "# If the discriminator is predicting \"real\" (output near 1) for adversarial examples,\n",
    "# then the detection evasion is successful.\n",
    "\n",
    "# You can also compare the classifier's performance on original vs adversarial samples:\n",
    "# Original test accuracy\n",
    "test_loss, test_accuracy = model.evaluate(X_test, y_test)\n",
    "print(f\"Test Loss: {test_loss}\")\n",
    "print(f\"Test Accuracy: {test_accuracy}\")\n",
    "\n",
    "original_predictions = discriminator.predict(X_test)\n",
    "original_accuracy = (original_predictions >= 0.5).mean()\n",
    "print(f\"Original accuracy: {original_accuracy:.4f}\")\n",
    "\n",
    "test_loss, test_accuracy = discriminator.evaluate(X_test, y_test)\n",
    "print(f\"Test Loss: {test_loss}\")\n",
    "print(f\"Test Accuracy: {test_accuracy}\")\n",
    "\n",
    "# Adversarial test accuracy\n",
    "adversarial_accuracy = (predictions_on_adversarial >= 0.5).mean()\n",
    "print(f\"Adversarial accuracy: {adversarial_accuracy:.4f}\")\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the CSV file\n",
    "csv_file = \"netflow_data_1.csv\"\n",
    "data = pd.read_csv(csv_file)  # Skip the first row if it contains metadata\n",
    "data\n",
    "# ['id.orig_addr','id.orig_port','id.resp_haddr','id.resp_pport','proto_enum','duration_interval','conn_state_string','orig_pkts_count','orig_ip_bytes_count','resp_pkts_count','resp_bytes', 'Category']\n",
    "filtered_flows = data[data['da'] == '172.20.10.2']\n",
    "selected_features = ['sp', 'dp', 'pr', 'td', 'flg', 'ibyt', 'ipkt', 'opkt', 'obyt']\n",
    "filtered_flows = filtered_flows[selected_features]\n",
    "filtered_flows['flg'] = filtered_flows['flg'].map(lambda flg: 4 if flg == '......S.' else flg)\n",
    "filtered_flows['flg'] = filtered_flows['flg'].map(lambda flg: 4 if flg == '........' else flg)\n",
    "filtered_flows['pr'] = filtered_flows['pr'].map(lambda pr: 1 if pr == 'TCP' else pr)\n",
    "filtered_flows['pr'] = filtered_flows['pr'].map(lambda pr: 2 if pr == 'UDP' else pr)\n",
    "filtered_flows = filtered_flows.rename(columns={\n",
    "    'sp': 'id.orig_port',\n",
    "    'dp': 'id.resp_pport',\n",
    "    'pr': 'proto_enum',\n",
    "    'td': 'duration_interval',\n",
    "    'flg': 'conn_state_string',\n",
    "    'ibyt': 'orig_pkts_count',\n",
    "    'ipkt': 'orig_ip_bytes_count',\n",
    "    'opkt': 'resp_pkts_count',\n",
    "    'obyt': 'resp_bytes'\n",
    "})\n",
    "for col in filtered_flows.columns:\n",
    "    if filtered_flows[col].dtype == 'object':  # Check if the column contains strings\n",
    "        filtered_flows[col] = filtered_flows[col].astype(float)  # Convert to float first\n",
    "\n",
    "# Now convert all numeric columns to integers\n",
    "filtered_flows = filtered_flows.astype(int)\n",
    "\n",
    "model.predict(filtered_flows)\n",
    "# filtered_flows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
