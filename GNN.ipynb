{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With a GNN we can learn patterns of the relationship between nodes and the connection's characteristics to identify anomalies in the behaviour.\n",
    "We should include this metrics: Accuracy, False Positive Rate , Precision, Recall and F1-score. https://ieeexplore.ieee.org/document/9776097/figures#figures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from torch_geometric.data import Data, DataLoader\n",
    "from torch_geometric.nn import GCNConv, global_mean_pool\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Load data\n",
    "df = pd.read_csv(\"df_ben_ddos.csv\")  \n",
    "features = df.drop(columns=[\"Category\"]).values\n",
    "labels = df[\"Category\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Characteristic's Normalization \n",
    "scaler = MinMaxScaler()\n",
    "features = scaler.fit_transform(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. tensor converter\n",
    "x = torch.tensor(features, dtype=torch.float)\n",
    "y = torch.tensor(labels, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Graphs\n",
    "def create_graph(x, y, k_neighbors=5):\n",
    "    num_nodes = x.shape[0]\n",
    "    edge_index = []\n",
    "    for i in range(num_nodes):\n",
    "        for j in range(max(0, i-k_neighbors), min(num_nodes, i+k_neighbors+1)):\n",
    "            if i != j:  \n",
    "                edge_index.append([i, j])\n",
    "    edge_index = torch.tensor(edge_index, dtype=torch.long).t().contiguous()\n",
    "    return Data(x=x, edge_index=edge_index, y=y)\n",
    "\n",
    "graph_data = create_graph(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Train and Test\n",
    "train_mask, test_mask = train_test_split(range(graph_data.num_nodes), test_size=0.2, random_state=42)\n",
    "graph_data.train_mask = torch.tensor(train_mask, dtype=torch.long)\n",
    "graph_data.test_mask = torch.tensor(test_mask, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Creating the GNN model\n",
    "class GNN(torch.nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super(GNN, self).__init__()\n",
    "        self.conv1 = GCNConv(input_dim, hidden_dim)\n",
    "        self.conv2 = GCNConv(hidden_dim, hidden_dim)\n",
    "        self.fc = torch.nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "        x = self.conv1(x, edge_index).relu()\n",
    "        x = self.conv2(x, edge_index).relu()\n",
    "        x = global_mean_pool(x, data.batch)  # Global pooling\n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. Model configuration\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = GNN(input_dim=x.size(1), hidden_dim=64, output_dim=2).to(device)\n",
    "data = graph_data.to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "criterion = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8. Training\n",
    "def train():\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    out = model(data)\n",
    "    loss = criterion(out[data.train_mask], data.y[data.train_mask])\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return loss.item()\n",
    "\n",
    "# def test():\n",
    "#     model.eval()\n",
    "#     with torch.no_grad():\n",
    "#         logits = model(data)\n",
    "#         preds = logits.argmax(dim=1)\n",
    "#         correct = preds[data.test_mask] == data.y[data.test_mask]\n",
    "#         accuracy = int(correct.sum()) / int(data.test_mask.sum())\n",
    "#     return accuracy\n",
    "\n",
    "def test():\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        logits = model(graph_data)\n",
    "        preds = logits.argmax(dim=1).cpu().numpy()  # Predicted labels\n",
    "        true_labels = graph_data.y.cpu().numpy()  # True labels\n",
    "\n",
    "        # Filter only test data\n",
    "        test_indices = graph_data.test_mask.cpu().numpy()\n",
    "        preds = preds[test_indices]\n",
    "        true_labels = true_labels[test_indices]\n",
    "\n",
    "        # Calculate confusion matrix\n",
    "        tn, fp, fn, tp = confusion_matrix(true_labels, preds, labels=[0, 1]).ravel()\n",
    "\n",
    "        # Calculate metrics\n",
    "        accuracy = (tp + tn) / (tn + fp + fn + tp)\n",
    "        fpr = fp / (fp + tn) if (fp + tn) > 0 else 0  # Avoid division by zero\n",
    "        precision = precision_score(true_labels, preds, pos_label=1)\n",
    "        recall = recall_score(true_labels, preds, pos_label=1)\n",
    "        f1 = f1_score(true_labels, preds, pos_label=1)\n",
    "\n",
    "    return accuracy, fpr, precision, recall, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hola\n",
      "adios\n",
      "deu\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 1548751 is out of bounds for dimension 0 with size 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [10], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m201\u001b[39m):\n\u001b[0;32m----> 2\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;28mprint\u001b[39m(epoch)\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m epoch \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m10\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "Cell \u001b[0;32mIn [9], line 9\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m out \u001b[38;5;241m=\u001b[39m model(data)\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdeu\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 9\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(\u001b[43mout\u001b[49m\u001b[43m[\u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_mask\u001b[49m\u001b[43m]\u001b[49m, data\u001b[38;5;241m.\u001b[39my[data\u001b[38;5;241m.\u001b[39mtrain_mask])\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhey\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     11\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "\u001b[0;31mIndexError\u001b[0m: index 1548751 is out of bounds for dimension 0 with size 1"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, 201):\n",
    "    loss = train()\n",
    "    print(epoch)\n",
    "    if epoch % 8 == 0:\n",
    "        accuracy, fpr, precision, recall, f1 = test()\n",
    "        print(f\"Epoch {epoch:03d}, Loss: {loss:.4f}, \"\n",
    "              f\"Accuracy: {accuracy:.4f}, FPR: {fpr:.4f}, \"\n",
    "              f\"Precision: {precision:.4f}, Recall: {recall:.4f}, F1-score: {f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "out.shape: torch.Size([1, 2])\n",
      "data.y.shape: torch.Size([2314095])\n",
      "data.train_mask.shape: torch.Size([1851276])\n",
      "data.train_mask.sum(): 2142024140205\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 1548751 is out of bounds for dimension 0 with size 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [17], line 26\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m accuracy\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m201\u001b[39m):\n\u001b[0;32m---> 26\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     27\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m epoch \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m10\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m     28\u001b[0m         test_acc \u001b[38;5;241m=\u001b[39m test()\n",
      "Cell \u001b[0;32mIn [17], line 11\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata.train_mask.shape: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdata\u001b[38;5;241m.\u001b[39mtrain_mask\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata.train_mask.sum(): \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdata\u001b[38;5;241m.\u001b[39mtrain_mask\u001b[38;5;241m.\u001b[39msum()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)  \u001b[38;5;66;03m# Número de muestras en el train_mask\u001b[39;00m\n\u001b[0;32m---> 11\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(\u001b[43mout\u001b[49m\u001b[43m[\u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_mask\u001b[49m\u001b[43m]\u001b[49m, data\u001b[38;5;241m.\u001b[39my[data\u001b[38;5;241m.\u001b[39mtrain_mask])\n\u001b[1;32m     12\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m     13\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n",
      "\u001b[0;31mIndexError\u001b[0m: index 1548751 is out of bounds for dimension 0 with size 1"
     ]
    }
   ],
   "source": [
    "# 8. Entrenamiento\n",
    "def train():\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    out = model(data)\n",
    "    print(f\"out.shape: {out.shape}\")\n",
    "    print(f\"data.y.shape: {data.y.shape}\")\n",
    "    print(f\"data.train_mask.shape: {data.train_mask.shape}\")\n",
    "    print(f\"data.train_mask.sum(): {data.train_mask.sum()}\")  # Número de muestras en el train_mask\n",
    "\n",
    "    loss = criterion(out[data.train_mask], data.y[data.train_mask])\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return loss.item()\n",
    "\n",
    "def test():\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        logits = model(data)\n",
    "        preds = logits.argmax(dim=1)\n",
    "        correct = preds[data.test_mask] == data.y[data.test_mask]\n",
    "        accuracy = int(correct.sum()) / int(data.test_mask.sum())\n",
    "    return accuracy\n",
    "\n",
    "for epoch in range(1, 201):\n",
    "    loss = train()\n",
    "    if epoch % 10 == 0:\n",
    "        test_acc = test()\n",
    "        print(f'Epoch {epoch:03d}, Loss: {loss:.4f}, Test Acc: {test_acc:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
